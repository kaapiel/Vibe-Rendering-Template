//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-21112126
// Cuda compilation tools, release 8.0, V8.0.43
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_30
.address_size 64

	// .globl	SDRConform

.visible .entry SDRConform(
	.param .u64 SDRConform_param_0,
	.param .u32 SDRConform_param_1,
	.param .u32 SDRConform_param_2,
	.param .u32 SDRConform_param_3,
	.param .u32 SDRConform_param_4,
	.param .align 16 .b8 SDRConform_param_5[16],
	.param .align 16 .b8 SDRConform_param_6[16],
	.param .align 16 .b8 SDRConform_param_7[16],
	.param .align 8 .b8 SDRConform_param_8[8],
	.param .f32 SDRConform_param_9,
	.param .f32 SDRConform_param_10,
	.param .f32 SDRConform_param_11,
	.param .f32 SDRConform_param_12,
	.param .f32 SDRConform_param_13,
	.param .align 16 .b8 SDRConform_param_14[16],
	.param .align 16 .b8 SDRConform_param_15[16],
	.param .align 16 .b8 SDRConform_param_16[16]
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<13>;
	.reg .f32 	%f<156>;
	.reg .b32 	%r<49>;
	.reg .b64 	%rd<14>;


	ld.param.u64 	%rd1, [SDRConform_param_0];
	ld.param.u32 	%r1, [SDRConform_param_1];
	ld.param.u32 	%r3, [SDRConform_param_2];
	ld.param.u32 	%r4, [SDRConform_param_3];
	ld.param.u32 	%r2, [SDRConform_param_4];
	ld.param.f32 	%f33, [SDRConform_param_5+8];
	ld.param.f32 	%f32, [SDRConform_param_5+4];
	ld.param.f32 	%f31, [SDRConform_param_5];
	ld.param.f32 	%f37, [SDRConform_param_6+8];
	ld.param.f32 	%f36, [SDRConform_param_6+4];
	ld.param.f32 	%f35, [SDRConform_param_6];
	ld.param.f32 	%f41, [SDRConform_param_7+8];
	ld.param.f32 	%f40, [SDRConform_param_7+4];
	ld.param.f32 	%f39, [SDRConform_param_7];
	ld.param.f32 	%f44, [SDRConform_param_8+4];
	ld.param.f32 	%f43, [SDRConform_param_8];
	ld.param.f32 	%f45, [SDRConform_param_9];
	ld.param.f32 	%f46, [SDRConform_param_10];
	ld.param.f32 	%f47, [SDRConform_param_11];
	ld.param.f32 	%f48, [SDRConform_param_12];
	ld.param.f32 	%f49, [SDRConform_param_13];
	ld.param.f32 	%f52, [SDRConform_param_14+8];
	ld.param.f32 	%f51, [SDRConform_param_14+4];
	ld.param.f32 	%f50, [SDRConform_param_14];
	ld.param.f32 	%f56, [SDRConform_param_15+8];
	ld.param.f32 	%f55, [SDRConform_param_15+4];
	ld.param.f32 	%f54, [SDRConform_param_15];
	ld.param.f32 	%f60, [SDRConform_param_16+8];
	ld.param.f32 	%f59, [SDRConform_param_16+4];
	ld.param.f32 	%f58, [SDRConform_param_16];
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %ntid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r8, %r6, %r5, %r7;
	mov.u32 	%r9, %ntid.y;
	mov.u32 	%r10, %ctaid.y;
	mov.u32 	%r11, %tid.y;
	mad.lo.s32 	%r12, %r9, %r10, %r11;
	setp.lt.s32	%p1, %r8, %r3;
	setp.lt.s32	%p2, %r12, %r4;
	and.pred  	%p3, %p1, %p2;
	@!%p3 bra 	BB0_12;
	bra.uni 	BB0_1;

BB0_1:
	setp.eq.s32	%p4, %r2, 0;
	@%p4 bra 	BB0_3;

	cvta.to.global.u64 	%rd2, %rd1;
	mad.lo.s32 	%r21, %r12, %r1, %r8;
	mul.wide.s32 	%rd3, %r21, 16;
	add.s64 	%rd4, %rd2, %rd3;
	ld.global.v4.f32 	{%f62, %f63, %f64, %f65}, [%rd4];
	mov.f32 	%f152, %f65;
	mov.f32 	%f151, %f64;
	mov.f32 	%f150, %f63;
	mov.f32 	%f149, %f62;
	bra.uni 	BB0_4;

BB0_3:
	cvta.to.global.u64 	%rd5, %rd1;
	mad.lo.s32 	%r30, %r12, %r1, %r8;
	mul.wide.s32 	%rd6, %r30, 8;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.v4.u16 	{%rs1, %rs2, %rs3, %rs4}, [%rd7];
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs1;
	cvt.f32.f16 	%f149, %temp;
	}
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs2;
	cvt.f32.f16 	%f150, %temp;
	}
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs3;
	cvt.f32.f16 	%f151, %temp;
	}
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs4;
	cvt.f32.f16 	%f152, %temp;
	}

BB0_4:
	mov.f32 	%f153, %f43;
	mov.f32 	%f154, %f44;
	setp.lt.ftz.f32	%p5, %f151, 0f00000000;
	setp.lt.ftz.f32	%p6, %f150, 0f00000000;
	setp.lt.ftz.f32	%p7, %f149, 0f00000000;
	abs.ftz.f32 	%f66, %f151;
	abs.ftz.f32 	%f67, %f150;
	abs.ftz.f32 	%f68, %f149;
	lg2.approx.ftz.f32 	%f69, %f66;
	mul.ftz.f32 	%f70, %f69, 0f4019999A;
	ex2.approx.ftz.f32 	%f71, %f70;
	lg2.approx.ftz.f32 	%f72, %f67;
	mul.ftz.f32 	%f73, %f72, 0f4019999A;
	ex2.approx.ftz.f32 	%f74, %f73;
	lg2.approx.ftz.f32 	%f75, %f68;
	mul.ftz.f32 	%f76, %f75, 0f4019999A;
	ex2.approx.ftz.f32 	%f77, %f76;
	neg.ftz.f32 	%f78, %f71;
	selp.f32	%f79, %f78, %f71, %p5;
	neg.ftz.f32 	%f80, %f74;
	selp.f32	%f81, %f80, %f74, %p6;
	neg.ftz.f32 	%f82, %f77;
	selp.f32	%f83, %f82, %f77, %p7;
	mul.ftz.f32 	%f84, %f32, %f81;
	fma.rn.ftz.f32 	%f85, %f31, %f79, %f84;
	fma.rn.ftz.f32 	%f15, %f33, %f83, %f85;
	mul.ftz.f32 	%f86, %f36, %f81;
	fma.rn.ftz.f32 	%f87, %f35, %f79, %f86;
	fma.rn.ftz.f32 	%f16, %f37, %f83, %f87;
	mul.ftz.f32 	%f88, %f40, %f81;
	fma.rn.ftz.f32 	%f89, %f39, %f79, %f88;
	fma.rn.ftz.f32 	%f90, %f41, %f83, %f89;
	add.ftz.f32 	%f91, %f15, %f16;
	add.ftz.f32 	%f17, %f90, %f91;
	setp.leu.ftz.f32	%p8, %f17, 0f358637BD;
	@%p8 bra 	BB0_6;

	div.approx.ftz.f32 	%f153, %f15, %f17;
	div.approx.ftz.f32 	%f154, %f16, %f17;

BB0_6:
	setp.lt.ftz.f32	%p9, %f16, 0f00000000;
	selp.f32	%f92, 0f00000000, %f16, %p9;
	mul.ftz.f32 	%f93, %f92, %f45;
	fma.rn.ftz.f32 	%f94, %f93, 0f42C7FAE1, 0f3F800000;
	lg2.approx.ftz.f32 	%f95, %f94;
	mul.ftz.f32 	%f96, %f95, 0f3E9A209B;
	fma.rn.ftz.f32 	%f22, %f96, 0f3F000000, 0fBF800000;
	setp.lt.ftz.f32	%p10, %f22, 0f00000000;
	neg.ftz.f32 	%f97, %f22;
	selp.f32	%f98, %f97, %f22, %p10;
	setp.gt.ftz.f32	%p11, %f98, 0f3F800000;
	selp.f32	%f23, 0f3F800000, %f98, %p11;
	setp.gt.ftz.f32	%p12, %f23, %f48;
	@%p12 bra 	BB0_8;
	bra.uni 	BB0_7;

BB0_8:
	sub.ftz.f32 	%f99, %f23, %f48;
	mov.f32 	%f100, 0f3F800000;
	sub.ftz.f32 	%f101, %f100, %f48;
	div.approx.ftz.f32 	%f102, %f99, %f101;
	sub.ftz.f32 	%f103, %f100, %f102;
	lg2.approx.ftz.f32 	%f104, %f103;
	mul.ftz.f32 	%f105, %f104, %f49;
	ex2.approx.ftz.f32 	%f106, %f105;
	sub.ftz.f32 	%f107, %f100, %f106;
	sub.ftz.f32 	%f108, %f100, %f47;
	fma.rn.ftz.f32 	%f155, %f108, %f107, %f47;
	bra.uni 	BB0_9;

BB0_7:
	mul.ftz.f32 	%f155, %f23, %f46;

BB0_9:
	neg.ftz.f32 	%f109, %f155;
	selp.f32	%f110, %f109, %f155, %p10;
	add.ftz.f32 	%f111, %f110, 0f3F800000;
	mov.f32 	%f112, 0f41200000;
	lg2.approx.ftz.f32 	%f113, %f112;
	mul.ftz.f32 	%f114, %f113, %f111;
	ex2.approx.ftz.f32 	%f115, %f114;
	add.ftz.f32 	%f116, %f115, 0fBF800000;
	mul.ftz.f32 	%f117, %f116, 0f3C257EB5;
	mul.ftz.f32 	%f118, %f153, %f117;
	div.approx.ftz.f32 	%f119, %f118, %f154;
	mov.f32 	%f120, 0f3F800000;
	sub.ftz.f32 	%f121, %f120, %f153;
	sub.ftz.f32 	%f122, %f121, %f154;
	mul.ftz.f32 	%f123, %f122, %f117;
	div.approx.ftz.f32 	%f124, %f123, %f154;
	mul.ftz.f32 	%f125, %f51, %f117;
	fma.rn.ftz.f32 	%f126, %f50, %f119, %f125;
	fma.rn.ftz.f32 	%f127, %f52, %f124, %f126;
	mul.ftz.f32 	%f128, %f55, %f117;
	fma.rn.ftz.f32 	%f129, %f54, %f119, %f128;
	fma.rn.ftz.f32 	%f130, %f56, %f124, %f129;
	mul.ftz.f32 	%f131, %f59, %f117;
	fma.rn.ftz.f32 	%f132, %f58, %f119, %f131;
	fma.rn.ftz.f32 	%f133, %f60, %f124, %f132;
	setp.lt.ftz.f32	%p14, %f127, 0f00000000;
	setp.lt.ftz.f32	%p15, %f130, 0f00000000;
	setp.lt.ftz.f32	%p16, %f133, 0f00000000;
	abs.ftz.f32 	%f134, %f127;
	abs.ftz.f32 	%f135, %f130;
	abs.ftz.f32 	%f136, %f133;
	lg2.approx.ftz.f32 	%f137, %f134;
	mul.ftz.f32 	%f138, %f137, 0f3ED55555;
	ex2.approx.ftz.f32 	%f139, %f138;
	lg2.approx.ftz.f32 	%f140, %f135;
	mul.ftz.f32 	%f141, %f140, 0f3ED55555;
	ex2.approx.ftz.f32 	%f142, %f141;
	lg2.approx.ftz.f32 	%f143, %f136;
	mul.ftz.f32 	%f144, %f143, 0f3ED55555;
	ex2.approx.ftz.f32 	%f145, %f144;
	neg.ftz.f32 	%f146, %f139;
	selp.f32	%f28, %f146, %f139, %p14;
	neg.ftz.f32 	%f147, %f142;
	selp.f32	%f29, %f147, %f142, %p15;
	neg.ftz.f32 	%f148, %f145;
	selp.f32	%f30, %f148, %f145, %p16;
	@%p4 bra 	BB0_11;

	cvta.to.global.u64 	%rd8, %rd1;
	mad.lo.s32 	%r39, %r12, %r1, %r8;
	mul.wide.s32 	%rd9, %r39, 16;
	add.s64 	%rd10, %rd8, %rd9;
	st.global.v4.f32 	[%rd10], {%f30, %f29, %f28, %f152};
	bra.uni 	BB0_12;

BB0_11:
	cvta.to.global.u64 	%rd11, %rd1;
	mad.lo.s32 	%r48, %r12, %r1, %r8;
	mul.wide.s32 	%rd12, %r48, 8;
	add.s64 	%rd13, %rd11, %rd12;
	{
	.reg .b16 %temp;
	cvt.rn.ftz.f16.f32 	%temp, %f152;
	mov.b16 	%rs9, %temp;
}
	{
	.reg .b16 %temp;
	cvt.rn.ftz.f16.f32 	%temp, %f28;
	mov.b16 	%rs10, %temp;
}
	{
	.reg .b16 %temp;
	cvt.rn.ftz.f16.f32 	%temp, %f29;
	mov.b16 	%rs11, %temp;
}
	{
	.reg .b16 %temp;
	cvt.rn.ftz.f16.f32 	%temp, %f30;
	mov.b16 	%rs12, %temp;
}
	st.global.v4.u16 	[%rd13], {%rs12, %rs11, %rs10, %rs9};

BB0_12:
	ret;
}


