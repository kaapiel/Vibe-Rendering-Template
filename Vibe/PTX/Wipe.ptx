//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-21112126
// Cuda compilation tools, release 8.0, V8.0.43
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_30
.address_size 64

	// .globl	WipeKernel

.visible .entry WipeKernel(
	.param .u64 WipeKernel_param_0,
	.param .u64 WipeKernel_param_1,
	.param .u64 WipeKernel_param_2,
	.param .u32 WipeKernel_param_3,
	.param .u32 WipeKernel_param_4,
	.param .u32 WipeKernel_param_5,
	.param .u32 WipeKernel_param_6,
	.param .u32 WipeKernel_param_7,
	.param .u32 WipeKernel_param_8,
	.param .u32 WipeKernel_param_9,
	.param .u32 WipeKernel_param_10,
	.param .u32 WipeKernel_param_11,
	.param .u32 WipeKernel_param_12,
	.param .f32 WipeKernel_param_13,
	.param .f32 WipeKernel_param_14,
	.param .f32 WipeKernel_param_15,
	.param .f32 WipeKernel_param_16,
	.param .f32 WipeKernel_param_17,
	.param .f32 WipeKernel_param_18,
	.param .f32 WipeKernel_param_19
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<37>;
	.reg .f32 	%f<136>;
	.reg .b32 	%r<29>;
	.reg .b64 	%rd<31>;


	ld.param.u64 	%rd6, [WipeKernel_param_0];
	ld.param.u64 	%rd7, [WipeKernel_param_1];
	ld.param.u64 	%rd8, [WipeKernel_param_2];
	ld.param.u32 	%r6, [WipeKernel_param_3];
	ld.param.u32 	%r7, [WipeKernel_param_4];
	ld.param.u32 	%r8, [WipeKernel_param_5];
	ld.param.u32 	%r9, [WipeKernel_param_6];
	ld.param.u32 	%r10, [WipeKernel_param_7];
	ld.param.u32 	%r11, [WipeKernel_param_8];
	ld.param.u32 	%r12, [WipeKernel_param_9];
	ld.param.u32 	%r13, [WipeKernel_param_10];
	ld.param.u32 	%r14, [WipeKernel_param_11];
	ld.param.u32 	%r15, [WipeKernel_param_12];
	ld.param.f32 	%f71, [WipeKernel_param_13];
	ld.param.f32 	%f72, [WipeKernel_param_14];
	ld.param.f32 	%f73, [WipeKernel_param_15];
	ld.param.f32 	%f74, [WipeKernel_param_16];
	ld.param.f32 	%f75, [WipeKernel_param_17];
	ld.param.f32 	%f76, [WipeKernel_param_18];
	ld.param.f32 	%f77, [WipeKernel_param_19];
	mov.u32 	%r16, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r1, %r16, %r17, %r18;
	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mov.u32 	%r21, %tid.y;
	mad.lo.s32 	%r2, %r19, %r20, %r21;
	setp.ge.s32	%p1, %r1, %r12;
	add.s32 	%r22, %r14, %r12;
	setp.lt.s32	%p2, %r1, %r22;
	and.pred  	%p3, %p1, %p2;
	setp.ge.s32	%p4, %r2, %r13;
	and.pred  	%p5, %p3, %p4;
	add.s32 	%r23, %r15, %r13;
	setp.lt.s32	%p6, %r2, %r23;
	and.pred  	%p7, %p5, %p6;
	@!%p7 bra 	BB0_21;
	bra.uni 	BB0_1;

BB0_1:
	cvta.to.global.u64 	%rd9, %rd7;
	sub.s32 	%r24, %r10, %r12;
	add.s32 	%r3, %r24, %r1;
	sub.s32 	%r25, %r11, %r13;
	add.s32 	%r4, %r25, %r2;
	cvt.rn.f32.u32	%f78, %r1;
	cvt.rn.f32.u32	%f79, %r2;
	mul.ftz.f32 	%f80, %f79, %f77;
	fma.rn.ftz.f32 	%f81, %f78, %f76, %f80;
	add.ftz.f32 	%f1, %f81, %f74;
	add.ftz.f32 	%f2, %f81, %f75;
	setp.ltu.ftz.f32	%p8, %f2, 0f3F800000;
	mad.lo.s32 	%r26, %r4, %r7, %r3;
	cvt.s64.s32	%rd1, %r26;
	mul.wide.s32 	%rd10, %r26, 16;
	add.s64 	%rd2, %rd9, %rd10;
	@%p8 bra 	BB0_6;
	bra.uni 	BB0_2;

BB0_6:
	cvta.to.global.u64 	%rd14, %rd6;
	setp.le.ftz.f32	%p10, %f2, 0f00000000;
	setp.le.ftz.f32	%p11, %f1, 0f00000000;
	and.pred  	%p12, %p10, %p11;
	mad.lo.s32 	%r27, %r4, %r6, %r3;
	cvt.s64.s32	%rd3, %r27;
	mul.wide.s32 	%rd15, %r27, 16;
	add.s64 	%rd4, %rd14, %rd15;
	@%p12 bra 	BB0_14;
	bra.uni 	BB0_7;

BB0_14:
	setp.eq.s32	%p15, %r9, 0;
	@%p15 bra 	BB0_16;

	ld.global.v4.f32 	{%f112, %f113, %f114, %f115}, [%rd4];
	mov.f32 	%f131, %f115;
	mov.f32 	%f130, %f114;
	mov.f32 	%f129, %f113;
	mov.f32 	%f128, %f112;
	bra.uni 	BB0_17;

BB0_2:
	setp.eq.s32	%p9, %r9, 0;
	@%p9 bra 	BB0_4;

	ld.global.v4.f32 	{%f82, %f83, %f84, %f85}, [%rd2];
	mov.f32 	%f119, %f85;
	mov.f32 	%f118, %f84;
	mov.f32 	%f117, %f83;
	mov.f32 	%f116, %f82;
	bra.uni 	BB0_5;

BB0_7:
	setp.eq.s32	%p13, %r9, 0;
	@%p13 bra 	BB0_9;

	ld.global.v4.f32 	{%f86, %f87, %f88, %f89}, [%rd4];
	mov.f32 	%f123, %f89;
	mov.f32 	%f122, %f88;
	mov.f32 	%f121, %f87;
	mov.f32 	%f120, %f86;
	bra.uni 	BB0_10;

BB0_4:
	mul.wide.s32 	%rd12, %r26, 8;
	add.s64 	%rd13, %rd9, %rd12;
	ld.global.v4.u16 	{%rs1, %rs2, %rs3, %rs4}, [%rd13];
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs1;
	cvt.f32.f16 	%f116, %temp;
	}
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs2;
	cvt.f32.f16 	%f117, %temp;
	}
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs3;
	cvt.f32.f16 	%f118, %temp;
	}
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs4;
	cvt.f32.f16 	%f119, %temp;
	}

BB0_5:
	mov.f32 	%f132, %f116;
	mov.f32 	%f133, %f117;
	mov.f32 	%f134, %f118;
	mov.f32 	%f135, %f119;
	bra.uni 	BB0_18;

BB0_16:
	shl.b64 	%rd23, %rd3, 3;
	add.s64 	%rd24, %rd14, %rd23;
	ld.global.v4.u16 	{%rs25, %rs26, %rs27, %rs28}, [%rd24];
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs25;
	cvt.f32.f16 	%f128, %temp;
	}
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs26;
	cvt.f32.f16 	%f129, %temp;
	}
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs27;
	cvt.f32.f16 	%f130, %temp;
	}
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs28;
	cvt.f32.f16 	%f131, %temp;
	}

BB0_17:
	mov.f32 	%f132, %f128;
	mov.f32 	%f133, %f129;
	mov.f32 	%f134, %f130;
	mov.f32 	%f135, %f131;
	bra.uni 	BB0_18;

BB0_9:
	shl.b64 	%rd17, %rd3, 3;
	add.s64 	%rd18, %rd14, %rd17;
	ld.global.v4.u16 	{%rs9, %rs10, %rs11, %rs12}, [%rd18];
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs9;
	cvt.f32.f16 	%f120, %temp;
	}
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs10;
	cvt.f32.f16 	%f121, %temp;
	}
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs11;
	cvt.f32.f16 	%f122, %temp;
	}
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs12;
	cvt.f32.f16 	%f123, %temp;
	}

BB0_10:
	@%p13 bra 	BB0_12;

	ld.global.v4.f32 	{%f90, %f91, %f92, %f93}, [%rd2];
	mov.f32 	%f127, %f93;
	mov.f32 	%f126, %f92;
	mov.f32 	%f125, %f91;
	mov.f32 	%f124, %f90;
	bra.uni 	BB0_13;

BB0_12:
	shl.b64 	%rd20, %rd1, 3;
	add.s64 	%rd21, %rd9, %rd20;
	ld.global.v4.u16 	{%rs17, %rs18, %rs19, %rs20}, [%rd21];
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs17;
	cvt.f32.f16 	%f124, %temp;
	}
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs18;
	cvt.f32.f16 	%f125, %temp;
	}
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs19;
	cvt.f32.f16 	%f126, %temp;
	}
	{
	.reg .b16 %temp;
	mov.b16 	%temp, %rs20;
	cvt.f32.f16 	%f127, %temp;
	}

BB0_13:
	mov.f32 	%f94, 0f00000000;
	max.ftz.f32 	%f95, %f1, %f94;
	mov.f32 	%f96, 0f3F800000;
	min.ftz.f32 	%f97, %f95, %f96;
	sub.ftz.f32 	%f98, %f71, %f120;
	fma.rn.ftz.f32 	%f99, %f98, %f97, %f120;
	sub.ftz.f32 	%f100, %f72, %f121;
	fma.rn.ftz.f32 	%f101, %f100, %f97, %f121;
	sub.ftz.f32 	%f102, %f73, %f122;
	fma.rn.ftz.f32 	%f103, %f102, %f97, %f122;
	sub.ftz.f32 	%f104, %f96, %f123;
	fma.rn.ftz.f32 	%f105, %f104, %f97, %f123;
	max.ftz.f32 	%f106, %f2, %f94;
	min.ftz.f32 	%f107, %f106, %f96;
	sub.ftz.f32 	%f108, %f124, %f99;
	fma.rn.ftz.f32 	%f132, %f107, %f108, %f99;
	sub.ftz.f32 	%f109, %f125, %f101;
	fma.rn.ftz.f32 	%f133, %f107, %f109, %f101;
	sub.ftz.f32 	%f110, %f126, %f103;
	fma.rn.ftz.f32 	%f134, %f107, %f110, %f103;
	sub.ftz.f32 	%f111, %f127, %f105;
	fma.rn.ftz.f32 	%f135, %f107, %f111, %f105;

BB0_18:
	mad.lo.s32 	%r28, %r2, %r8, %r1;
	cvt.s64.s32	%rd5, %r28;
	setp.eq.s32	%p16, %r9, 0;
	@%p16 bra 	BB0_20;

	cvta.to.global.u64 	%rd25, %rd8;
	shl.b64 	%rd26, %rd5, 4;
	add.s64 	%rd27, %rd25, %rd26;
	st.global.v4.f32 	[%rd27], {%f132, %f133, %f134, %f135};
	bra.uni 	BB0_21;

BB0_20:
	cvta.to.global.u64 	%rd28, %rd8;
	shl.b64 	%rd29, %rd5, 3;
	add.s64 	%rd30, %rd28, %rd29;
	{
	.reg .b16 %temp;
	cvt.rn.ftz.f16.f32 	%temp, %f135;
	mov.b16 	%rs33, %temp;
}
	{
	.reg .b16 %temp;
	cvt.rn.ftz.f16.f32 	%temp, %f134;
	mov.b16 	%rs34, %temp;
}
	{
	.reg .b16 %temp;
	cvt.rn.ftz.f16.f32 	%temp, %f133;
	mov.b16 	%rs35, %temp;
}
	{
	.reg .b16 %temp;
	cvt.rn.ftz.f16.f32 	%temp, %f132;
	mov.b16 	%rs36, %temp;
}
	st.global.v4.u16 	[%rd30], {%rs36, %rs35, %rs34, %rs33};

BB0_21:
	ret;
}


